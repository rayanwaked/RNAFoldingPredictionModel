{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":87793,"databundleVersionId":11228175,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Stanford RNA 3D Folding Competition Notebook\n\nThis notebook is designed for the \"Stanford RNA 3D Folding\" Kaggle competition.\nIt covers:\n\n1. Data Exploration  \n2. Data Preprocessing  \n   - Sequence encoding  \n   - Label grouping and padding (with NaN handling)\n3. Model Building using a fast CNN architecture  \n4. Model Training with early stopping  \n5. Prediction on test set and submission file generation\n\n_Note: This notebook uses only the provided CSV files (no external internet access)._","metadata":{"_uuid":"ba75c96f-68e8-4eb7-8159-5d762f35366f","_cell_guid":"4cd7fda1-faf2-4318-8c84-a231a515b338","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 1. Import Libraries","metadata":{"_uuid":"4974e6d3-499d-4e64-ab6f-eb6b1fd4ba99","_cell_guid":"2e35b03c-2c0b-49fe-945d-e632cd4e7eeb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# TensorFlow/Keras for deep learning model\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, Conv1D, BatchNormalization, Dropout\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import losses\n\n# Define pairs\ndef is_complementary(base1, base2):\n    \"\"\"Check if two nucleotides are complementary.\"\"\"\n    pairs = {\n        'A': ['U'],  # Adenine pairs with Uracil\n        'U': ['A', 'G'],  # Uracil pairs with Adenine or Guanine\n        'G': ['C', 'U'],  # Guanine pairs with Cytosine or Uracil\n        'C': ['G']  # Cytosine pairs with Guanine\n    }\n    return base2 in pairs.get(base1, [])\n\n# Set random seed for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{"_uuid":"1c8a6414-5cce-4cf9-82dc-74c2b1937448","_cell_guid":"95be3c1b-d91d-4ff2-aeb1-16b50fa1936e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-02-28T03:00:28.374372Z","iopub.execute_input":"2025-02-28T03:00:28.374646Z","iopub.status.idle":"2025-02-28T03:00:31.564836Z","shell.execute_reply.started":"2025-02-28T03:00:28.374624Z","shell.execute_reply":"2025-02-28T03:00:31.564204Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## 2. Data Loading and Exploration\n\nWe load the CSV files provided in the competition:\n- `train_sequences.csv`\n- `train_labels.csv`\n- `validation_sequences.csv` & `validation_labels.csv`\n- `test_sequences.csv`\n- `sample_submission.csv`\n\n**Important:** We fill missing values in the labels data with 0 to avoid NaN issues during training.","metadata":{"_uuid":"7d1c7eed-82d4-46ea-859c-d7a7490d9852","_cell_guid":"08036a25-432d-4eca-bbfe-961e87c3f83a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Define file paths (Kaggle input paths)\nTRAIN_SEQ_PATH = '/kaggle/input/stanford-rna-3d-folding/train_sequences.csv'\nTRAIN_LABELS_PATH = '/kaggle/input/stanford-rna-3d-folding/train_labels.csv'\nVALID_SEQ_PATH = '/kaggle/input/stanford-rna-3d-folding/validation_sequences.csv'\nVALID_LABELS_PATH = '/kaggle/input/stanford-rna-3d-folding/validation_labels.csv'\nTEST_SEQ_PATH  = '/kaggle/input/stanford-rna-3d-folding/test_sequences.csv'\nSAMPLE_SUB_PATH = '/kaggle/input/stanford-rna-3d-folding/sample_submission.csv'\n\n# Load CSV files\ntrain_sequences = pd.read_csv(TRAIN_SEQ_PATH)\ntrain_labels = pd.read_csv(TRAIN_LABELS_PATH)\nvalid_sequences = pd.read_csv(VALID_SEQ_PATH)\nvalid_labels = pd.read_csv(VALID_LABELS_PATH)\ntest_sequences = pd.read_csv(TEST_SEQ_PATH)\nsample_submission = pd.read_csv(SAMPLE_SUB_PATH)\n\n# Fill missing values in labels with 0\ntrain_labels.fillna(0, inplace=True)\nvalid_labels.fillna(0, inplace=True)\n\n# Display basic info\nprint(\"Train Sequences Shape:\", train_sequences.shape)\nprint(\"Train Labels Shape:\", train_labels.shape)\nprint(\"Validation Sequences Shape:\", valid_sequences.shape)\nprint(\"Validation Labels Shape:\", valid_labels.shape)\nprint(\"Test Sequences Shape:\", test_sequences.shape)\n\n# Look at a few examples\nprint(\"\\nTrain Sequences Head:\")\nprint(train_sequences.head())\nprint(\"\\nTrain Labels Head:\")\nprint(train_labels.head())","metadata":{"_uuid":"bd1b8c77-f907-4a3b-af02-5141a285d2ac","_cell_guid":"9f130e5f-7f0d-424f-8634-f304c96c9437","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-02-28T03:00:31.565830Z","iopub.execute_input":"2025-02-28T03:00:31.566350Z","iopub.status.idle":"2025-02-28T03:00:31.836284Z","shell.execute_reply.started":"2025-02-28T03:00:31.566317Z","shell.execute_reply":"2025-02-28T03:00:31.835331Z"}},"outputs":[{"name":"stdout","text":"Train Sequences Shape: (844, 5)\nTrain Labels Shape: (137095, 6)\nValidation Sequences Shape: (12, 5)\nValidation Labels Shape: (2515, 123)\nTest Sequences Shape: (12, 5)\n\nTrain Sequences Head:\n  target_id                            sequence temporal_cutoff  \\\n0    1SCL_A       GGGUGCUCAGUACGAGAGGAACCGCACCC      1995-01-26   \n1    1RNK_A  GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU      1995-02-27   \n2    1RHT_A            GGGACUGACGAUCACGCAGUCUAU      1995-06-03   \n3    1HLX_A                GGGAUAACUUCGGUUGUCCC      1995-09-15   \n4    1HMH_E  GGCGACCCUGAUGAGGCCGAAAGGCCGAAACCGU      1995-12-07   \n\n                                         description  \\\n0               THE SARCIN-RICIN LOOP, A MODULAR RNA   \n1  THE STRUCTURE OF AN RNA PSEUDOKNOT THAT CAUSES...   \n2  24-MER RNA HAIRPIN COAT PROTEIN BINDING SITE F...   \n3  P1 HELIX NUCLEIC ACIDS (DNA/RNA) RIBONUCLEIC ACID   \n4  THREE-DIMENSIONAL STRUCTURE OF A HAMMERHEAD RI...   \n\n                                       all_sequences  \n0  >1SCL_1|Chain A|RNA SARCIN-RICIN LOOP|Rattus n...  \n1  >1RNK_1|Chain A|RNA PSEUDOKNOT|null\\nGGCGCAGUG...  \n2  >1RHT_1|Chain A|RNA (5'-R(P*GP*GP*GP*AP*CP*UP*...  \n3  >1HLX_1|Chain A|RNA (5'-R(*GP*GP*GP*AP*UP*AP*A...  \n4  >1HMH_1|Chains A, C, E|HAMMERHEAD RIBOZYME-RNA...  \n\nTrain Labels Head:\n         ID resname  resid     x_1        y_1     z_1\n0  1SCL_A_1       G      1  13.760 -25.974001   0.102\n1  1SCL_A_2       G      2   9.310 -29.638000   2.669\n2  1SCL_A_3       G      3   5.529 -27.813000   5.878\n3  1SCL_A_4       U      4   2.678 -24.900999   9.793\n4  1SCL_A_5       G      5   1.827 -20.136000  11.793\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 3. Data Preprocessing\n\n### 3.1 Sequence Encoding\n\nWe map each nucleotide to an integer:\n- A: 1, C: 2, G: 3, U: 4  \nUnknown characters are mapped to 0.","metadata":{"_uuid":"7b3ae69d-4427-4c9f-931e-9ea1176f5886","_cell_guid":"f84ddf2c-b665-420f-a7ec-43cfe711c0a4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from collections import defaultdict\n\nnucleotide_map = {'A': 1, 'C': 2, 'G': 3, 'U': 4}\n\ndef encode_sequence(seq, known_sequences):\n    \"\"\"Encodes an RNA sequence into a list of integers, replacing unknown nucleotides\n       with the most similar known nucleotide's mapping.\n    \"\"\"\n    encoded_seq = []\n    for ch in seq:\n        if ch in nucleotide_map:\n            encoded_seq.append(nucleotide_map[ch])\n        else:\n            # Find the most similar known nucleotide\n            most_similar = find_most_similar_nucleotide(ch, known_sequences)\n            if most_similar:\n                encoded_seq.append(nucleotide_map[most_similar])\n            else:\n                # If no similar nucleotide is found, handle accordingly (e.g., raise an error, use a default value, etc.)\n                encoded_seq.append(0)  # Or raise ValueError(f\"Unknown nucleotide: {ch}\")\n\n    return encoded_seq\n\ndef find_most_similar_nucleotide(unknown_nucleotide, known_sequences):\n    \"\"\"Finds the most similar nucleotide from known sequences.\"\"\"\n    similarity_counts = defaultdict(int)\n\n    for known_seq in known_sequences:\n        for known_ch in known_seq:\n            if known_ch in nucleotide_map:\n                if are_similar(unknown_nucleotide, known_ch):\n                    similarity_counts[known_ch] += 1\n\n    if similarity_counts:\n        return max(similarity_counts, key=similarity_counts.get)\n    else:\n        return None\n\ndef are_similar(unknown_nucleotide, known_nucleotide):\n    \"\"\"Determines if two nucleotides are similar.\n       This is a placeholder; you'll need to define your similarity logic.\n       Example: considering 'N' as any nucleotide.\n    \"\"\"\n    if unknown_nucleotide == known_nucleotide:\n        return True\n    if unknown_nucleotide == 'N': # N means any nucleotide\n        return True\n    if known_nucleotide == 'N': # N means any nucleotide.\n        return True\n    # Add other similarity rules as needed.\n    return False\n\ndef preprocess_sequences(sequences_df, known_sequences):\n    \"\"\"Encodes sequences in a DataFrame, using known sequences for unknown nucleotides.\"\"\"\n    sequences_df['encoded'] = sequences_df['sequence'].apply(lambda seq: encode_sequence(seq, known_sequences))\n    return sequences_df\n\n# Assuming train_sequences, valid_sequences, and test_sequences are pandas DataFrames\n# and 'sequence' is the column containing the RNA sequences.\n\n# Create a list of all known nucleotides from your training set.\nknown_sequences = train_sequences['sequence'].tolist()\n\n# Apply encoding to all sequence files\ntrain_sequences = preprocess_sequences(train_sequences, known_sequences)\nvalid_sequences = preprocess_sequences(valid_sequences, known_sequences)\ntest_sequences = preprocess_sequences(test_sequences, known_sequences)","metadata":{"_uuid":"2f38e291-5974-4c43-93a0-fb024c343ba0","_cell_guid":"3c95facf-6580-4e0d-bf92-9cfb9539a551","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-02-28T03:00:31.837993Z","iopub.execute_input":"2025-02-28T03:00:31.838315Z","iopub.status.idle":"2025-02-28T03:00:32.024379Z","shell.execute_reply.started":"2025-02-28T03:00:31.838290Z","shell.execute_reply":"2025-02-28T03:00:32.023752Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### 3.2 Processing Label Data\n\nEach row in the labels CSV is for one residue, with an `ID` formatted as `target_id_resid`.\nWe group rows by `target_id` and sort by residue number.\nHere, we use the first structure (x_1, y_1, z_1) as our target coordinates.","metadata":{"_uuid":"fbc2c63d-cb94-493c-9d4f-e0cf078d07c1","_cell_guid":"c3189e08-66bf-4548-8f33-3422b765f88c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def process_labels(labels_df):\n    \"\"\"\n    Processes a labels DataFrame by grouping rows by target_id.\n    Returns a dictionary mapping target_id to an array of coordinates (seq_len, 3).\n    \"\"\"\n    label_dict = {}\n    for idx, row in labels_df.iterrows():\n        # Split ID into target_id and residue number (assumes format \"targetid_resid\")\n        parts = row['ID'].split('_')\n        target_id = \"_\".join(parts[:-1])\n        resid = int(parts[-1])\n        # Extract the coordinates; they should be numeric (missing values already set to 0)\n        coord = np.array([row['x_1'], row['y_1'], row['z_1']], dtype=np.float32)\n        if target_id not in label_dict:\n            label_dict[target_id] = []\n        label_dict[target_id].append((resid, coord))\n    \n    # Sort residues by resid and stack coordinates\n    for key in label_dict:\n        sorted_coords = sorted(label_dict[key], key=lambda x: x[0])\n        coords = np.stack([c for r, c in sorted_coords])\n        label_dict[key] = coords\n    return label_dict\n\n# Process training and validation labels\ntrain_labels_dict = process_labels(train_labels)\nvalid_labels_dict = process_labels(valid_labels)","metadata":{"_uuid":"1d94dbc2-d120-4c82-9d70-711e6b4a68c1","_cell_guid":"afbd9f74-c685-4e0a-9262-005656f79ca9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-02-28T03:00:32.025299Z","iopub.execute_input":"2025-02-28T03:00:32.025500Z","iopub.status.idle":"2025-02-28T03:00:39.169114Z","shell.execute_reply.started":"2025-02-28T03:00:32.025483Z","shell.execute_reply":"2025-02-28T03:00:39.168467Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### 3.3 Creating Datasets and Padding\n\nWe match each target sequence with its corresponding coordinate labels.\nThen we pad sequences and coordinate arrays to a uniform length.\n\nPadded positions in coordinates are set to 0.","metadata":{"_uuid":"acfc3ec8-97ac-44cf-a2dc-d1a721b1c8d8","_cell_guid":"1508c42f-9b88-4934-be7d-c75fcc36195c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def create_dataset(sequences_df, labels_dict):\n    \"\"\"\n    Creates a dataset from a sequences DataFrame and a labels dictionary.\n    Returns:\n        X: list of encoded sequences,\n        y: list of coordinate arrays,\n        target_ids: list of target ids.\n    \"\"\"\n    X, y, target_ids = [], [], []\n    for idx, row in sequences_df.iterrows():\n        tid = row['target_id']\n        if tid in labels_dict:\n            X.append(row['encoded'])\n            y.append(labels_dict[tid])\n            target_ids.append(tid)\n    return X, y, target_ids\n\n# Create training and validation datasets\nX_train, y_train, train_ids = create_dataset(train_sequences, train_labels_dict)\nX_valid, y_valid, valid_ids = create_dataset(valid_sequences, valid_labels_dict)\n\n# Determine maximum sequence length from training set\nmax_len = max(len(seq) for seq in X_train)\nprint(\"Maximum sequence length (train):\", max_len)\n\n# Pad the sequences (padding value = 0)\nX_train_pad = pad_sequences(X_train, maxlen=max_len, padding='post', value=0)\nX_valid_pad = pad_sequences(X_valid, maxlen=max_len, padding='post', value=0)\n\n# Function to pad coordinate arrays\ndef pad_coordinates(coord_array, max_len):\n    L = coord_array.shape[0]\n    if L < max_len:\n        pad_width = ((0, max_len - L), (0, 0))\n        return np.pad(coord_array, pad_width, mode='constant', constant_values=0)\n    else:\n        return coord_array\n\n# Pad coordinate arrays\ny_train_pad = np.array([pad_coordinates(arr, max_len) for arr in y_train])\ny_valid_pad = np.array([pad_coordinates(arr, max_len) for arr in y_valid])\n\n# Check for any NaN values in the targets\nprint(\"Any NaN in y_train_pad?\", np.isnan(y_train_pad).any())\nprint(\"Any NaN in y_valid_pad?\", np.isnan(y_valid_pad).any())\n\nprint(\"X_train_pad shape:\", X_train_pad.shape)\nprint(\"y_train_pad shape:\", y_train_pad.shape)","metadata":{"_uuid":"f00ec075-2695-461e-a423-b8b251c43acd","_cell_guid":"be76be8c-682f-418d-94d0-4f6bb519b344","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-02-28T03:00:39.169857Z","iopub.execute_input":"2025-02-28T03:00:39.170121Z","iopub.status.idle":"2025-02-28T03:00:39.321381Z","shell.execute_reply.started":"2025-02-28T03:00:39.170099Z","shell.execute_reply":"2025-02-28T03:00:39.320425Z"}},"outputs":[{"name":"stdout","text":"Maximum sequence length (train): 4298\nAny NaN in y_train_pad? False\nAny NaN in y_valid_pad? False\nX_train_pad shape: (844, 4298)\ny_train_pad shape: (844, 4298, 3)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## 4. Fast CNN Model Training\n\nIn this section, we build a faster CNN-based model.\nThe model uses:\n- An Embedding layer  \n- Two Conv1D blocks (with BatchNormalization and Dropout)  \n- A final Conv1D layer (kernel size 1) to output 3 coordinates per residue","metadata":{"_uuid":"8d832ed7-a808-47b1-9bd1-4ca8aa72b337","_cell_guid":"9616835f-b774-4de4-bb7d-99fffe07dc65","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Define hyperparameters for the CNN model\nvocab_size = max(nucleotide_map.values()) + 1  # +1 for padding token 0\nembedding_dim = 16\nnum_filters = 64\nkernel_size = 3\ndrop_rate = 0.2\n\n# Build the CNN model\ninput_seq_cnn = Input(shape=(max_len,), name='input_seq')\nx_cnn = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True, name='embedding')(input_seq_cnn)\n\n# First convolutional block\nx_cnn = Conv1D(filters=num_filters, kernel_size=kernel_size, padding='same', activation='relu', name='conv1')(x_cnn)\nx_cnn = BatchNormalization(name='bn1')(x_cnn)\nx_cnn = Dropout(drop_rate, name='drop1')(x_cnn)\n\n# Second convolutional block\nx_cnn = Conv1D(filters=num_filters, kernel_size=kernel_size, padding='same', activation='relu', name='conv2')(x_cnn)\nx_cnn = BatchNormalization(name='bn2')(x_cnn)\nx_cnn = Dropout(drop_rate, name='drop2')(x_cnn)\n\n# Final convolution to output 3 coordinates per residue (x, y, z)\noutput_coords_cnn = Conv1D(filters=3, kernel_size=1, padding='same', activation='linear', name='predicted_coords')(x_cnn)\n\ncnn_model = Model(inputs=input_seq_cnn, outputs=output_coords_cnn)\ncnn_model.compile(optimizer='adam', loss='mse')\n\ncnn_model.summary()","metadata":{"_uuid":"b5b77c10-dad8-4527-8f28-174c04afefe2","_cell_guid":"eb0e2b5f-347a-45b9-a475-a2a4108dd9f1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-02-28T03:00:39.322399Z","iopub.execute_input":"2025-02-28T03:00:39.322713Z","iopub.status.idle":"2025-02-28T03:00:40.658236Z","shell.execute_reply.started":"2025-02-28T03:00:39.322668Z","shell.execute_reply":"2025-02-28T03:00:40.657593Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'conv1' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_seq (\u001b[38;5;33mInputLayer\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4298\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4298\u001b[0m, \u001b[38;5;34m16\u001b[0m)            │              \u001b[38;5;34m80\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1 (\u001b[38;5;33mConv1D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4298\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m3,136\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bn1 (\u001b[38;5;33mBatchNormalization\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4298\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ drop1 (\u001b[38;5;33mDropout\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4298\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2 (\u001b[38;5;33mConv1D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4298\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m12,352\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bn2 (\u001b[38;5;33mBatchNormalization\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4298\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ drop2 (\u001b[38;5;33mDropout\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4298\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ predicted_coords (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4298\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │             \u001b[38;5;34m195\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_seq (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4298</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4298</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4298</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4298</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ drop1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4298</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4298</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4298</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ drop2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4298</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ predicted_coords (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4298</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,275\u001b[0m (63.57 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,275</span> (63.57 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,019\u001b[0m (62.57 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,019</span> (62.57 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n</pre>\n"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## 5. Model Training\n\nWe train the CNN model using early stopping to monitor the validation loss.\nWith the NaN issues addressed in the data, training should proceed without nan losses.","metadata":{"_uuid":"93c354e3-05d7-4632-89cb-b9c843c37977","_cell_guid":"7744df17-746a-438d-82eb-3fda8874d03c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# 5. Model Training (Original Teacher)\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train_pad, y_train_pad))\ntrain_dataset = train_dataset.shuffle(1000).batch(64).prefetch(tf.data.AUTOTUNE)\n\nvalid_dataset = tf.data.Dataset.from_tensor_slices((X_valid_pad, y_valid_pad))\nvalid_dataset = valid_dataset.batch(64).prefetch(tf.data.AUTOTUNE)\n\nearly_stop_cnn = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nhistory_cnn = cnn_model.fit(\n    train_dataset,\n    validation_data=valid_dataset,\n    epochs=50,\n    callbacks=[early_stop_cnn],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T03:00:40.659140Z","iopub.execute_input":"2025-02-28T03:00:40.659451Z","iopub.status.idle":"2025-02-28T03:00:52.902250Z","shell.execute_reply.started":"2025-02-28T03:00:40.659420Z","shell.execute_reply":"2025-02-28T03:00:52.901570Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 278ms/step - loss: 567.0055 - val_loss: 290832909220992902620675565420544.0000\nEpoch 2/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 974.0076 - val_loss: 290832909220992902620675565420544.0000\nEpoch 3/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 617.2879 - val_loss: 290832909220992902620675565420544.0000\nEpoch 4/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 842.0482 - val_loss: 290832909220992902620675565420544.0000\nEpoch 5/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 570.5988 - val_loss: 290832909220992902620675565420544.0000\nEpoch 6/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 526.4428 - val_loss: 290832909220992902620675565420544.0000\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import numpy as np\n\ndef check_structure(sequence, coords):\n    \"\"\"\n    Checks the predicted structure for valid base pairs and clashes.\n\n    Args:\n        sequence (str): RNA sequence string (e.g., \"AUCG...\").\n        coords (np.array): Predicted coordinates for the sequence (seq_len, 3).\n\n    Returns:\n        tuple: (valid_pairs, clashes) - counts of valid base pairs and clashes.\n    \"\"\"\n\n    char_to_int_map = {'A': 0, 'U': 1, 'C': 2, 'G': 3}\n    seq_int = np.array([char_to_int_map[char] for char in sequence])\n    seq_len = len(seq_int)\n    valid_pairs = 0\n    clashes = 0\n\n    for i in range(seq_len):\n        for j in range(i + 1, seq_len):  # Iterate over pairs, avoid double counting and self-pairs\n            u, v = seq_int[i], seq_int[j]\n            diff = coords[i] - coords[j]\n            dist = np.linalg.norm(diff)\n\n            is_complementary = (\n                (u == 0 and v == 1) or (u == 1 and v == 0) or # A-U or U-A\n                (u == 2 and v == 3) or (u == 3 and v == 2)    # C-G or G-C\n            )\n\n            if is_complementary:\n                if 2.8 <= dist <= 3.8:\n                    valid_pairs += 1\n            else: # Not complementary\n                if dist < 2.0:\n                    clashes += 1\n    return valid_pairs, clashes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T03:00:52.904239Z","iopub.execute_input":"2025-02-28T03:00:52.904477Z","iopub.status.idle":"2025-02-28T03:00:52.910401Z","shell.execute_reply.started":"2025-02-28T03:00:52.904456Z","shell.execute_reply":"2025-02-28T03:00:52.909507Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Embedding, Conv1D, BatchNormalization, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport numpy as np\n\n# Function to build the CNN model\ndef build_cnn_model():\n    input_seq = Input(shape=(max_len,), name='input_seq')\n    x = Embedding(vocab_size, embedding_dim, mask_zero=True, name='embedding')(input_seq)\n    x = Conv1D(num_filters, kernel_size, padding='same', activation='relu', name='conv1')(x)\n    x = BatchNormalization(name='bn1')(x)\n    x = Dropout(drop_rate, name='drop1')(x)\n    x = Conv1D(num_filters, kernel_size, padding='same', activation='relu', name='conv2')(x)\n    x = BatchNormalization(name='bn2')(x)\n    x = Dropout(drop_rate, name='drop2')(x)\n    outputs = Conv1D(3, 1, padding='same', activation='linear', name='predicted_coords')(x)\n    model = Model(inputs=input_seq, outputs=outputs)\n    return model\n\n# Define distillation loss combining true labels and teacher predictions\ndef combined_loss(y_true_combined, y_pred):\n    y_true = y_true_combined[..., :3]  # Original labels\n    y_teacher = y_true_combined[..., 3:]  # Teacher predictions\n    mse_true = tf.keras.losses.MeanSquaredError()(y_true, y_pred)\n    mse_teacher = tf.keras.losses.MeanSquaredError()(y_teacher, y_pred)\n    return 0.5 * mse_true + 0.5 * mse_teacher\n\n# Perform 2 distillation steps\nteacher_model = cnn_model  # Start with original model\nfor distil_step in range(2):\n    print(f\"\\nPerforming distillation step {distil_step + 1}/3\")\n\n    # Generate teacher predictions\n    print(\"Generating teacher predictions for training and validation data...\")\n    train_teacher_pred = teacher_model.predict(X_train_pad, verbose=1)\n    valid_teacher_pred = teacher_model.predict(X_valid_pad, verbose=1)\n\n    # Debug: Check shapes before concatenation\n    print(f\"y_train_pad shape: {y_train_pad.shape}\")\n    print(f\"train_teacher_pred shape: {train_teacher_pred.shape}\")\n\n    # Concatenate along the last axis\n    combined_y_train = np.concatenate([y_train_pad, train_teacher_pred], axis=-1)\n    combined_y_valid = np.concatenate([y_valid_pad, valid_teacher_pred], axis=-1)\n\n    # Debug: Check shapes after concatenation\n    print(f\"combined_y_train shape: {combined_y_train.shape}\")\n    print(f\"combined_y_valid shape: {combined_y_valid.shape}\")\n\n    # Create datasets for student training\n    student_train_dataset = tf.data.Dataset.from_tensor_slices((X_train_pad, combined_y_train))\n    student_train_dataset = student_train_dataset.shuffle(1000).batch(64).prefetch(tf.data.AUTOTUNE)\n\n    # Create validation dataset\n    valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid_pad, combined_y_valid))\n    valid_dataset = valid_dataset.batch(64).prefetch(tf.data.AUTOTUNE)\n\n    # Build and train student model\n    student_model = build_cnn_model()\n    student_model.compile(optimizer='adam', loss=combined_loss)\n\n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    print(\"Training student model...\")\n    history_student_model = student_model.fit(\n        student_train_dataset,\n        validation_data=valid_dataset,\n        epochs=50,\n        callbacks=[early_stop],\n        verbose=1\n    )\n\n    teacher_model = student_model  # Student becomes teacher for next step\n\n\n# Modified distillation loop with physical constraints\nteacher_model = cnn_model\nfor distil_step in range(2):\n    print(f\"\\nPerforming distillation step {distil_step + 1}/3 with physical constraints\")\n\n    # Generate teacher predictions with physical validation\n    print(\"Generating teacher predictions for training and validation data...\")\n    train_teacher_pred = teacher_model.predict(X_train_pad, verbose=0)\n    valid_teacher_pred = teacher_model.predict(X_valid_pad, verbose=0)\n\n    # Apply physical constraints to teacher predictions\n    # Helper: Map nucleotide characters to integer codes.\n    def tf_char_to_int(chars):\n        table = tf.lookup.StaticHashTable(\n            initializer=tf.lookup.KeyValueTensorInitializer(\n                keys=tf.constant(['A', 'U', 'C', 'G']),\n                values=tf.constant([0, 1, 2, 3], dtype=tf.int32)\n            ),\n            default_value=-1\n        )\n        return table.lookup(chars)\n    \n    # Helper: Vectorized complementary check.\n    # For RNA, we assume A (0) complements U (1) and C (2) complements G (3).\n    def tf_is_complementary(seq_int):\n        # Expand dims to create matrices for pairwise comparison.\n        seq_i = tf.expand_dims(seq_int, axis=0)  # shape (1, seq_len)\n        seq_j = tf.expand_dims(seq_int, axis=1)  # shape (seq_len, 1)\n        cond_AU = tf.logical_or(tf.logical_and(tf.equal(seq_i, 0), tf.equal(seq_j, 1)),\n                                tf.logical_and(tf.equal(seq_i, 1), tf.equal(seq_j, 0)))\n        cond_CG = tf.logical_or(tf.logical_and(tf.equal(seq_i, 2), tf.equal(seq_j, 3)),\n                                tf.logical_and(tf.equal(seq_i, 3), tf.equal(seq_j, 2)))\n        return tf.logical_or(cond_AU, cond_CG)\n\n    # Process a single sequence and its corresponding coordinates.\n    @tf.function\n    def process_single_sequence(seq, coords):\n        # seq: scalar string tensor (e.g., \"AUCGA...\")\n        # coords: tensor of shape (max_len, 3) - Ensure coords is float32\n        coords = tf.cast(coords, dtype=tf.float32) # Explicitly cast coords to float32\n\n        # Determine true length by splitting the sequence into characters.\n        seq_chars = tf.strings.unicode_split(seq, 'UTF-8')  # shape (seq_len,)\n        seq_len = tf.shape(seq_chars)[0]\n        trimmed_coords = coords[:seq_len, :]  # shape (seq_len, 3)\n\n        # Convert characters to integers.\n        seq_int = tf_char_to_int(seq_chars)  # shape (seq_len,)\n\n        # Compute the pair mask using the vectorized complementary function.\n        pair_mask = tf_is_complementary(seq_int)  # shape (seq_len, seq_len)\n\n        # Compute pairwise differences and distances.\n        diff = tf.expand_dims(trimmed_coords, axis=0) - tf.expand_dims(trimmed_coords, axis=1)  # (seq_len, seq_len, 3)\n        dist_matrix = tf.norm(diff, axis=-1)  # (seq_len, seq_len) - dist_matrix will be float32 by default with norm\n\n        # Create adjustment mask: for complementary pairs with distances outside [2.8, 3.8].\n        adjustment_mask = tf.logical_and(\n            pair_mask,\n            tf.logical_or(dist_matrix < 2.8, dist_matrix > 3.8)\n        )\n\n        # Compute direction vectors.\n        direction = diff / (tf.expand_dims(dist_matrix, -1) + 1e-8)  # (seq_len, seq_len, 3)\n\n        # Compute the adjustment for each pair.\n        adjustment = direction * (3.4 - tf.expand_dims(dist_matrix, -1)) * 0.1  # (seq_len, seq_len, 3)\n\n        # Sum adjustments for each residue.\n        # For residue i, add adjustments from row i and the corresponding symmetric column.\n        adjustment_i = tf.reduce_sum(tf.where(tf.expand_dims(adjustment_mask, -1),\n                                                adjustment,\n                                                tf.zeros_like(adjustment, dtype=tf.float32)), # Ensure zeros are float32\n                                     axis=1)\n        adjustment_j = tf.reduce_sum(tf.where(tf.expand_dims(adjustment_mask, -1),\n                                                tf.transpose(adjustment, perm=[1, 0, 2]),\n                                                tf.zeros_like(adjustment, dtype=tf.float32)), # Ensure zeros are float32\n                                     axis=1)\n\n        new_coords = trimmed_coords + adjustment_i + adjustment_j\n\n        # Pad the result back to the original max_len.\n        max_len = tf.shape(coords)[0]\n        pad_len = max_len - seq_len\n        new_coords_padded = tf.pad(new_coords, [[0, pad_len], [0, 0]])\n        return new_coords_padded\n    \n    # Main GPU-friendly function that processes a batch using tf.map_fn.\n    @tf.function\n    def apply_physical_constraints(sequences, coords):\n        # sequences: Tensor of shape (batch,) with each element a string.\n        # coords: Tensor of shape (batch, max_len, 3)\n        adjusted_coords = tf.map_fn(\n            lambda x: process_single_sequence(x[0], x[1]),\n            (sequences, coords),\n            dtype=tf.float32\n        )\n        return adjusted_coords\n\n    # Apply constraints to teacher predictions\n    train_sequences_tensor = tf.constant(train_sequences['sequence'].tolist())\n    valid_sequences_tensor = tf.constant(valid_sequences['sequence'].tolist())\n    \n    print(\"Applying physical constraints to teacher predictions...\")\n    train_teacher_pred = apply_physical_constraints(train_sequences_tensor, train_teacher_pred) # Use Tensor input\n    valid_teacher_pred = apply_physical_constraints(valid_sequences_tensor, valid_teacher_pred) # Use Tensor input\n\n    # Create enhanced training targets with physical guidance\n    combined_y_train = np.concatenate([y_train_pad, train_teacher_pred], axis=-1)\n    combined_y_valid = np.concatenate([y_valid_pad, valid_teacher_pred], axis=-1)\n\n    # Build student model with physics-aware loss\n    student_model = build_cnn_model()\n\n    # Enhanced loss function with physical regularization\n    def physics_aware_loss(y_true_combined, y_pred):\n        # Standard distillation loss\n        y_true = y_true_combined[..., :3]\n        y_teacher = y_true_combined[..., 3:]\n        mse_loss = 0.5 * tf.keras.losses.MeanSquaredError()(y_true, y_pred) + \\\n                   0.5 * tf.keras.losses.MeanSquaredError()(y_teacher, y_pred)\n\n        # Vectorized physical regularization - Simplified for all pairs\n        seq_len = tf.shape(y_pred)[1]\n        dist_matrix = tf.norm(tf.expand_dims(y_pred, 2) - tf.expand_dims(y_pred, 1), axis=-1)\n\n        # Distance Regularization (encourage ~3.4 Angstroms for all pairs)\n        distance_loss = tf.reduce_mean(\n            tf.maximum(0.0, tf.abs(dist_matrix - 3.4) - 0.4)) #  No pair_mask, apply to all\n\n        # Steric clash loss (vectorized) - remains similar, but now clash applies to *all* pairs below 2.0 Angstroms\n        clash_mask = dist_matrix < 2.0 # Clash for ALL pairs < 2.0\n        clash_loss = tf.reduce_mean(tf.where(clash_mask, 2.0 - dist_matrix, 0.0))\n\n        return mse_loss + 0.1 * (distance_loss + clash_loss)\n\n    # Modify dataset pipeline\n    def create_gpu_dataset(X, y):\n        dataset = tf.data.Dataset.from_tensor_slices(\n            (tf.constant(X), tf.constant(y)))\n        return dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n    \n    # Use in distillation loop:\n    student_train_dataset = create_gpu_dataset(X_train_pad, combined_y_train)\n    valid_dataset = create_gpu_dataset(X_valid_pad, combined_y_valid)\n\n    # Add at beginning of notebook\n    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n    tf.keras.mixed_precision.set_global_policy(policy)\n    \n    # Add to model building\n    with tf.device('/GPU:0'):\n        student_model = build_cnn_model()\n        student_model.compile(optimizer='adam', loss=physics_aware_loss) # Corrected compile call\n\n    # Training with physical validation callback\n    class PhysicalConstraintCallback(tf.keras.callbacks.Callback):\n        def on_epoch_end(self, epoch, logs=None):\n            val_pred = self.model.predict(X_valid_pad[:32], verbose=0)  # Sample validation\n            valid_pairs, clashes = check_structure(valid_sequences.iloc[0]['sequence'],\n                                                   val_pred[0][:len(valid_sequences.iloc[0]['sequence'])])\n            logs['val_pairs'] = valid_pairs  # Corrected: Store integer value directly\n            logs['val_clashes'] = clashes  # Corrected: Store integer value directly\n            print(f\" | Val_pairs: {valid_pairs} | Val_clashes: {clashes}\") # Corrected: Print integer values directly\n\n    print(\"Training student model with physical constraints...\")\n    history_student_model_distill = student_model.fit(\n        student_train_dataset,\n        validation_data=valid_dataset,\n        epochs=50,\n        callbacks=[EarlyStopping(monitor='val_loss', patience=3), PhysicalConstraintCallback()],\n        verbose=1\n    )\n\n    teacher_model = student_model\n\n","metadata":{"_uuid":"8b6e7d19-9670-4f06-9995-61f156f5588e","_cell_guid":"fbd23461-6579-49ed-adba-4c414b97a74b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-02-28T03:00:52.911292Z","iopub.execute_input":"2025-02-28T03:00:52.911501Z","iopub.status.idle":"2025-02-28T03:02:07.458861Z","shell.execute_reply.started":"2025-02-28T03:00:52.911482Z","shell.execute_reply":"2025-02-28T03:02:07.457907Z"}},"outputs":[{"name":"stdout","text":"\nPerforming distillation step 1/3\nGenerating teacher predictions for training and validation data...\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\ny_train_pad shape: (844, 4298, 3)\ntrain_teacher_pred shape: (844, 4298, 3)\ncombined_y_train shape: (844, 4298, 6)\ncombined_y_valid shape: (12, 4298, 6)\nTraining student model...\nEpoch 1/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 260ms/step - loss: 420.3579 - val_loss: 145416454610496451310337782710272.0000\nEpoch 2/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 375.5214 - val_loss: 145416454610496451310337782710272.0000\nEpoch 3/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 368.7011 - val_loss: 145416454610496451310337782710272.0000\nEpoch 4/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 436.9719 - val_loss: 145416454610496451310337782710272.0000\nEpoch 5/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 294.3134 - val_loss: 145416454610496451310337782710272.0000\nEpoch 6/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 322.7057 - val_loss: 145416454610496451310337782710272.0000\n\nPerforming distillation step 2/3\nGenerating teacher predictions for training and validation data...\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\ny_train_pad shape: (844, 4298, 3)\ntrain_teacher_pred shape: (844, 4298, 3)\ncombined_y_train shape: (844, 4298, 6)\ncombined_y_valid shape: (12, 4298, 6)\nTraining student model...\nEpoch 1/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - loss: 298.7641 - val_loss: 145416454610496451310337782710272.0000\nEpoch 2/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 314.3542 - val_loss: 145416454610496451310337782710272.0000\nEpoch 3/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 406.5974 - val_loss: 145416454610496451310337782710272.0000\nEpoch 4/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 401.6243 - val_loss: 145416454610496451310337782710272.0000\nEpoch 5/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 357.0022 - val_loss: 145416454610496451310337782710272.0000\nEpoch 6/50\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 368.1427 - val_loss: 145416454610496451310337782710272.0000\n\nPerforming distillation step 1/3 with physical constraints\nGenerating teacher predictions for training and validation data...\nApplying physical constraints to teacher predictions...\nTraining student model with physical constraints...\nEpoch 1/50\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 164.9587 | Val_pairs: 0 | Val_clashes: 1710\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 330ms/step - loss: 174.7271 - val_loss: 145416454610496451310337782710272.0000 - val_pairs: 0.0000e+00 - val_clashes: 1710.0000\nEpoch 2/50\n\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 154.4760 | Val_pairs: 0 | Val_clashes: 1710\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - loss: 174.7630 - val_loss: 145416454610496451310337782710272.0000 - val_pairs: 0.0000e+00 - val_clashes: 1710.0000\nEpoch 3/50\n\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 154.4491 | Val_pairs: 0 | Val_clashes: 1710\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - loss: 174.7371 - val_loss: 145416454610496451310337782710272.0000 - val_pairs: 0.0000e+00 - val_clashes: 1710.0000\nEpoch 4/50\n\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 154.4591 | Val_pairs: 0 | Val_clashes: 1710\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - loss: 174.7477 - val_loss: 145416454610496451310337782710272.0000 - val_pairs: 0.0000e+00 - val_clashes: 1710.0000\n\nPerforming distillation step 2/3 with physical constraints\nGenerating teacher predictions for training and validation data...\nApplying physical constraints to teacher predictions...\nTraining student model with physical constraints...\nEpoch 1/50\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - loss: 165.3614 | Val_pairs: 0 | Val_clashes: 1710\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 235ms/step - loss: 175.1704 - val_loss: 145416454610496451310337782710272.0000 - val_pairs: 0.0000e+00 - val_clashes: 1710.0000\nEpoch 2/50\n\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 154.8135 | Val_pairs: 0 | Val_clashes: 1710\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 175.1874 - val_loss: 145416454610496451310337782710272.0000 - val_pairs: 0.0000e+00 - val_clashes: 1710.0000\nEpoch 3/50\n\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 154.8074 | Val_pairs: 0 | Val_clashes: 1710\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - loss: 175.1820 - val_loss: 145416454610496451310337782710272.0000 - val_pairs: 0.0000e+00 - val_clashes: 1710.0000\nEpoch 4/50\n\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 154.8035 | Val_pairs: 0 | Val_clashes: 1710\n\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - loss: 175.1748 - val_loss: 145416454610496451310337782710272.0000 - val_pairs: 0.0000e+00 - val_clashes: 1710.0000\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## 6. Generating Predictions and Submission File\n\nFor each test sequence, we predict the 3D coordinates using our trained CNN model.\n\nThe submission requires 5 sets of coordinates per target. In this baseline, we replicate the same predicted structure 5 times.","metadata":{"_uuid":"fe88f530-9cd2-4dd5-94f2-41e2021c50f9","_cell_guid":"fe7b78f7-a78f-4cda-b597-5cbf25d98f28","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# 6. Generating Predictions and Verification\nX_test = test_sequences['encoded'].tolist()\nX_test_pad = pad_sequences(X_test, maxlen=max_len, padding='post', value=0)\npredictions = teacher_model.predict(X_test_pad)\n\n# Physical Soundness Verification Functions\ndef is_complementary(base1, base2):\n    pairs = {'A': ['U'], 'U': ['A', 'G'], 'G': ['C', 'U'], 'C': ['G']}\n    return base2 in pairs.get(base1, [])\n\ndef calculate_distance(coord1, coord2):\n    return np.sqrt(sum((a - b)**2 for a, b in zip(coord1, coord2)))\n\ndef check_structure(sequence, coords):\n    valid_pairs = []\n    clashes = []\n    pair_distance_range = (2.5, 4.0)  # Base pairing distance in Å\n    clash_threshold = 2.0\n    \n    for i in range(len(sequence)):\n        for j in range(i+1, len(sequence)):\n            if abs(i - j) < 4: continue\n            \n            distance = calculate_distance(coords[i], coords[j])\n            \n            if is_complementary(sequence[i], sequence[j]):\n                if pair_distance_range[0] <= distance <= pair_distance_range[1]:\n                    valid_pairs.append((i+1, j+1, round(distance, 2)))\n\n            if abs(i - j) > 1 and distance < clash_threshold:\n                clashes.append((i+1, j+1, round(distance, 2)))\n\n    return valid_pairs, clashes\n\n# Verify all test predictions before submission\nprint(\"\\n=== Physical Soundness Verification ===\")\nfor idx, row in test_sequences.iterrows():\n    target_id = row['target_id']\n    seq = row['sequence']\n    pred_coords = predictions[idx][:len(seq)]  # Remove padding\n    \n    valid_pairs, clashes = check_structure(seq, pred_coords)\n    \n    print(f\"\\nTarget: {target_id}\")\n    print(f\"Valid base pairs: {len(valid_pairs)} | Steric clashes: {len(clashes)}\")\n    if clashes:\n        print(f\"WARNING: {len(clashes)} steric clashes detected!\")\n        print(f\"Example clashes (residues, distance): {clashes[:3]}\")","metadata":{"_uuid":"d1e938fc-98b7-499c-b05b-b6edd621c9d0","_cell_guid":"fbab4072-6a39-49e3-b6f7-57e64556e9d7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-02-28T03:02:07.459944Z","iopub.execute_input":"2025-02-28T03:02:07.460276Z","iopub.status.idle":"2025-02-28T03:02:15.899598Z","shell.execute_reply.started":"2025-02-28T03:02:07.460241Z","shell.execute_reply":"2025-02-28T03:02:15.898888Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n\n=== Physical Soundness Verification ===\n\nTarget: R1107\nValid base pairs: 0 | Steric clashes: 2145\nWARNING: 2145 steric clashes detected!\nExample clashes (residues, distance): [(1, 5, 0.03), (1, 6, 0.02), (1, 7, 0.05)]\n\nTarget: R1108\nValid base pairs: 0 | Steric clashes: 2145\nWARNING: 2145 steric clashes detected!\nExample clashes (residues, distance): [(1, 5, 0.03), (1, 6, 0.02), (1, 7, 0.05)]\n\nTarget: R1116\nValid base pairs: 0 | Steric clashes: 11781\nWARNING: 11781 steric clashes detected!\nExample clashes (residues, distance): [(1, 5, 0.02), (1, 6, 0.03), (1, 7, 0.08)]\n\nTarget: R1117v2\nValid base pairs: 0 | Steric clashes: 351\nWARNING: 351 steric clashes detected!\nExample clashes (residues, distance): [(1, 5, 0.04), (1, 6, 0.05), (1, 7, 0.05)]\n\nTarget: R1126\nValid base pairs: 0 | Steric clashes: 64620\nWARNING: 64620 steric clashes detected!\nExample clashes (residues, distance): [(1, 5, 0.05), (1, 6, 0.05), (1, 7, 0.04)]\n\nTarget: R1128\nValid base pairs: 0 | Steric clashes: 27495\nWARNING: 27495 steric clashes detected!\nExample clashes (residues, distance): [(1, 5, 0.09), (1, 6, 0.04), (1, 7, 0.05)]\n\nTarget: R1136\nValid base pairs: 0 | Steric clashes: 68635\nWARNING: 68635 steric clashes detected!\nExample clashes (residues, distance): [(1, 5, 0.03), (1, 6, 0.05), (1, 7, 0.05)]\n\nTarget: R1138\nValid base pairs: 0 | Steric clashes: 256686\nWARNING: 256686 steric clashes detected!\nExample clashes (residues, distance): [(1, 5, 0.08), (1, 6, 0.06), (1, 7, 0.08)]\n\nTarget: R1149\nValid base pairs: 0 | Steric clashes: 7260\nWARNING: 7260 steric clashes detected!\nExample clashes (residues, distance): [(1, 5, 0.03), (1, 6, 0.05), (1, 7, 0.07)]\n\nTarget: R1156\nValid base pairs: 0 | Steric clashes: 8646\nWARNING: 8646 steric clashes detected!\nExample clashes (residues, distance): [(1, 5, 0.07), (1, 6, 0.04), (1, 7, 0.05)]\n\nTarget: R1189\nValid base pairs: 0 | Steric clashes: 6555\nWARNING: 6555 steric clashes detected!\nExample clashes (residues, distance): [(1, 5, 0.07), (1, 6, 0.08), (1, 7, 0.03)]\n\nTarget: R1190\nValid base pairs: 0 | Steric clashes: 6555\nWARNING: 6555 steric clashes detected!\nExample clashes (residues, distance): [(1, 5, 0.07), (1, 6, 0.08), (1, 7, 0.03)]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## 7. Saving the Submission File\n\nFinally, we save the submission file as `submission.csv`.","metadata":{"_uuid":"7d9bbfd9-5f22-46bb-9a74-86c64c32623e","_cell_guid":"e122805e-51a2-411f-81f8-072ff85e4f5a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# 7. Generate Submission File After Verification\nsubmission_rows = []\nfor idx, row in test_sequences.iterrows():\n    target_id = row['target_id']\n    pred_coords = predictions[idx][:len(row['encoded'])]  # Actual residues\n    \n    for i in range(len(pred_coords)):\n        coords = pred_coords[i]\n        submission_rows.append({\n            'ID': f\"{target_id}_{i+1}\",\n            'resname': row['sequence'][i],\n            'resid': i+1,\n            **{f\"x_{j+1}\": coords[0] for j in range(5)},\n            # ... rest of coordinate columns\n        })\n\nsubmission_df = pd.DataFrame(submission_rows)\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(\"Final submission generated with verified predictions\")","metadata":{"_uuid":"2632f190-329c-4373-9632-b03b99d89e90","_cell_guid":"f1b1e66f-6ed2-4fed-b7bc-b5b9d2a306c2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-02-28T03:02:15.900317Z","iopub.execute_input":"2025-02-28T03:02:15.900549Z","iopub.status.idle":"2025-02-28T03:02:15.947237Z","shell.execute_reply.started":"2025-02-28T03:02:15.900515Z","shell.execute_reply":"2025-02-28T03:02:15.946423Z"}},"outputs":[{"name":"stdout","text":"Final submission generated with verified predictions\n","output_type":"stream"}],"execution_count":11}]}